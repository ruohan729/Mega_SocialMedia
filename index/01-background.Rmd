<!--
This is for including Chapter 1.  Notice that it's also good practice to name your chunk.  This will help you debug potential issues as you knit.  The chunk above is called intro and the one below is called background.  Feel free to change the name of the Rmd file as you wish, but don't forget to change it here from 01-background.Rmd.
-->

<!--
The {#background} text after the chapter declaration will allow us to link throughout the document back to the beginning of of the background section.  These labels will automatically be generated (if not specified) by changing the spaces to hyphens and capital letters to lowercase.  Look for the reference to this label at the beginning of Chapter 2.
-->

# Background {#background .unnumbered}

## Social Media Variables {.unnumbered}

For this forecasting project, we focused on collecting social media data on selected topics. These selected topics are Coca-Cola, Pepsi, McDonald’s, Taco Bell, and “jobs”.  Coca-Cola was selected because it is their product’s demand that Scholle IPN is interested in forecasting. Pepsi was selected due to its position as the main competitor for Coca-Cola.  Meanwhile, McDonald’s and Taco Bell were chosen because they are the top quick service restaurant partners for Coca-Cola and Pepsi based on 2017 rankings (QSR Magazine, 2018). The topic "jobs" was selected to gather job-related tweets intended to capture economic activity in the United States and Canada.  Relationships between social media activity on these topics and the quantity of Coca-Cola bags ordered can be useful information for our forecasting models.

Twitter data is a combination of user-level tweets and company-level tweets, while Google Trend data is monthly trend value for our selected terms.  User-level tweet data were Twitter posts from regular online consumers tweeting about Coca-Cola, Pepsi, McDonald’s, Taco Bell, and “jobs.”  Company-level tweet data were Twitter posts by the official Twitter accounts of Coca-Cola, Pepsi, McDonald’s, and Taco Bell.  Meanwhile, Google Trends data was the trend value for Coca-Cola and the other selected topics on a given month.  T

## Sentiment Analysis {.unnumbered}

One method of quantifying text-based social media data for our forecasting models is by implementing sentiment analysis.  This is a technique in natural language processing that we use for each tweet to generate a numerical value signifying whether consumers have a positive or negative outlook on Coca-Cola, Pepsi, McDonald’s, Taco Bell, or "jobs".  Prior to conducting sentiment analysis, text processing steps must be conducted on tweets. The following steps were conducted on the tweets:

* Remove stop words on tweets
* Tokenize tweets
* Lemmatize tweets   

For this project, we only calculated sentiment scores for user-generated tweets because we assumed that tweets generated by the official company accounts are positively biased towards their own brand.  The R package sentimentR was used to calculate sentiment scores for each tweet. This package took into account additional information such as valence shifters and de-amplifiers resulting in a more accurate sentiment score (see Appendix A).  The sentiment scores for each selected term’s collective tweets per month was averaged at the monthly level to generate the monthly average sentiment score.  The monthly average sentiment score was then added as a variable to forecasting Coca-Cola bag orders.

## Stationarity and Differencing {.unnumbered}
An important step to consider when forecasting is to remove trends and seasonality from variables in order to make it stationary.  When time series data is stationary, it displays a stable mean and stable variance over time (Hyndman, 2018).  This means that it is less likely to produce spurious relationships and misleading results.  The KPSS test (Kwiatkowski, 1992) was conducted on each social media variable to determine its level of stationarity (Hyndman, 1992).  It was determined that the dependent variable, monthly quantity of Coca-Cola bag orders, is stationary.  This means that this variable requires no further transformations.  However, the independent variables diplayed varied results and required additional processing.  One way of transforming time series data to become stationary is the method of differencing.  Differencing is the method of subtracting the value of the current time step from the value of previous time step(s).  This method was applied to all social media variables to ensure that they were all stationary.  Figure 1 demonstrated how the method of differencing is able to remove trends from the monthly total user tweets.  The top half of the visual are time plots of the pre-differenced variables, while the bottom are time plots of the differenced variables.

```{r differencing, out.width="200px", fig.align="center", out.extra="angle = 0, scale=2.1", fig.cap="Differenced social media variables", echo=FALSE}
include_graphics(path = "figure/differencing.jpg")
```

## Dimension Reduction {.unnumbered}
When building forecasting models, it is important to be aware of their level of complexity.  In this project, we collected Twitter data with over a hundred features for a single tweet (tweet text, user profile data, etc.).  Using all of these features would have made our forecasting models highly complex and likely result in poor predictions.  Fortunately, the scope of this project limited the tweet information required for modeling to only a tweet’s text, number of likes, number of retweets, and number of replies.  However, the complexity of this project (relevant topics, social media data type, social media source) still left us with 46 total independent variables per observation (see Data section).  We used two main approaches in this project to further reduce our social media variable’s dimensions.

#### Method A - Principal Component Analysis {.unnumbered} 
The first method we used to reduce the dimensionality of our social media variables is principal component analysis (PCA).  PCA uses an orthogonal transformation of our variables into linearly uncorrelated variables called principal components (Kambhatla, 1997).   The advantage of PCA is that a limited number of principal components will explain the majority of the variance in the data.  This allowed us to discard the principal components that provide little additional information.  However, the major limitation for PCA is that it is generally less interpretable than using the original variables.
According to our PCA model of the social media variables,  our team identified seven principal components (Figure 2) as the optimal number of components.  These 7 components explained 97% of the variable's total variance, successfully reducing the overall social media variables of 46.

```{r pca, out.width="200px", fig.align="center", out.extra="angle = 0, scale=2.1", fig.cap="Variable Explained vs. Principal Components Plot", echo=FALSE}
include_graphics(path = "figure/pca.png")
```

#### Method B - Cross Correlation {.unnumbered}
The second method we employed to reduce our total features is by testing independent variables for cross correlation with the dependent variable (Brockwell, 1991).  This identified how many months in advance a social media variable could lead to an increase or decrease in Coca-Cola bag orders. For example, consider when a social media variable was found to be significantly positively correlated with Coca-Cola bag orders at lag t-1.  If this social media variable has a positive cross correlation value for the current month, then an increase in Coca-Cola bag orders can be expected the following month. For this method, we limit our analysis to only the previous six lags of an independent variable due to the dynamic nature of social media discussions. What is popular this month, may no longer be popular in subsequent months. We checked for cross-correlation on the original variables as well as the principal component variables. The cross correlation approach identified eight lags from the social media variables that were cross correlated with Coca-Cola bag orders (Table 1).

--------------------------------------------------------------
  Social Media Variable                    Significant Lag   
--------------------------------  ---------------------------- 
  Coca-Cola  Account tweets                    t-1                     
  
  Taco Bell  Account tweets                    t-1                       
  
  Job Google Trend                             t-2                        
  
  McDonald’s Google Trend                      t-2
  
  McDonald’s Account replies                   t-5
  
  Taco Bell Google Trend                       t-5
  
  McDonald’s Google Trend                      t-5
  
  Pepsi Account tweets                         t-6
--------------------------------  ---------------------------- 
Table: (\#tab:inher) Social Media Variables with Specified Lags

In addition, we identified seven lags from principal components that are cross correlated with Coca-Cola bag orders (Table 2).  

----------------------------------------------------------
  Principal Component             Significant Lag   
------------------------- -------------------------------- 
           PC7                            t-1                     
  
           PC6                            t-2                          
  
           PC4                            t-2                         
  
           PC6                            t-3
  
           PC4                            t-3
  
           PC3                            t-5
  
           PC3                            t-6
------------------------- ----------------------------------------- 
Table: (\#tab:inher) Principal Components with Specified Lags

## Ensemble Modeling {.unnumbered}
A variety of different machine learning models is used to forecast future Coca-Cola bag orders (see Modeling Framework).  In addition to these machine learning models, this project demonstrated the strength of the ensemble model approach (Pavlyshenko, 2019). The main assumption to ensemble modeling is that combining all lower-level models results in a more accurate, overall model. An ensemble model is able to highlight the strength of each individual model and account for each model’s weaknesses.  The ensemble model approach will be used in this project to produce the best model.


\newpage
